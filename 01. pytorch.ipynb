{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220707_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6cFjMW1dMvv"
      },
      "outputs": [],
      "source": [
        "# GPU 정보 확인\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 마운트\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "r4M5JURjdSAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor 초기화"
      ],
      "metadata": {
        "id": "vLUsLCAx4wML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = [1, 2]\n",
        "x_tensor = torch.tensor(x)\n",
        "\n",
        "y = [[1, 1], [2, 2]]\n",
        "y_tensor = torch.tensor(y)\n",
        "\n",
        "z = [[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]]\n",
        "z_tensor = torch.tensor(z)\n",
        "\n",
        "print(type(x))\n",
        "print(type(y))\n",
        "print(type(z), \"\\n\")\n",
        "\n",
        "print(type(x_tensor))\n",
        "print(type(y_tensor))\n",
        "print(type(z_tensor), \"\\n\")\n",
        "\n",
        "print(x_tensor.type())\n",
        "print(y_tensor.type())\n",
        "print(z_tensor.type(), \"\\n\")"
      ],
      "metadata": {
        "id": "ex-PuQQnm6iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numpy를 이용한 Tensor 초기화"
      ],
      "metadata": {
        "id": "80TQ5XlQ40fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x_np = np.array(x)\n",
        "x_tensor_2 = torch.tensor(x_np)\n",
        "x_tensor_3 = torch.from_numpy(x_np)\n",
        "\n",
        "print(x_tensor_2.type())\n",
        "print(x_tensor_3.type())"
      ],
      "metadata": {
        "id": "2h_4ZePmtI8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기존 Tensor와 Torch 함수를 이용한 초기화"
      ],
      "metadata": {
        "id": "s7k5trCy5CLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_zeros = torch.zeros_like(x_tensor)\n",
        "x_ones = torch.ones_like(x_tensor)\n",
        "x_rand = torch.rand_like(x_tensor, dtype=torch.float)\n",
        "\n",
        "print(x_zeros)\n",
        "print(x_ones)\n",
        "print(x_rand)"
      ],
      "metadata": {
        "id": "Jp99NrJ6tmQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Shape"
      ],
      "metadata": {
        "id": "ENpfCIlg5AXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_tensor.shape)\n",
        "print(y_tensor.shape)\n",
        "print(z_tensor.shape, \"\\n\")\n",
        "\n",
        "print(x_tensor.size())\n",
        "print(y_tensor.size())\n",
        "print(z_tensor.size())"
      ],
      "metadata": {
        "id": "qdhZL-rQsKbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shape과 Torch 함수를 이용한 초기화"
      ],
      "metadata": {
        "id": "XJZi51Fe5J_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = [2, 3]\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "rand_tensor = torch.rand(shape)\n",
        "\n",
        "print(\"{}\\n\".format(zeros_tensor))\n",
        "print(\"{}\\n\".format(ones_tensor))\n",
        "print(\"{}\\n\".format(rand_tensor))"
      ],
      "metadata": {
        "id": "IlV_rW5P0-li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.rand(4, 2, 3)\n",
        "y = torch.rand(4, 3, 2)\n",
        "\n",
        "print(\"Shape of the result: {}\\n\".format(torch.matmul(x, y).shape))\n",
        "print(torch.matmul(x, y))"
      ],
      "metadata": {
        "id": "yEIdPWFANPQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshape, Matrix multiplication 실습"
      ],
      "metadata": {
        "id": "5eoCKBK05IxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\"\"\"\n",
        "모든 원소가 무작위인 4x3 shape의 tensor x를 선언하고,\n",
        "이를 3x4의 shape으로 변환한 후 tensor y에 저장하고(hint: .reshape()),\n",
        "matri multiplication을 수행한 결과를 출력하시오.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "RXhTK28U1dB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cosine Similarity 실습"
      ],
      "metadata": {
        "id": "-nJZVjS7P2wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "모든 원소가 무작위인 4x2 shape의 tensor x, y를 선언하고,\n",
        "두 tensor의 cosine similarity를 구하시오.\n",
        "\n",
        "Hint: .dot() and .norm()\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "46rJdb8dP4io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Layer Neural Network"
      ],
      "metadata": {
        "id": "-DMmF2kAYeng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SingleLayerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SingleLayerNet, self).__init__()\n",
        "\n",
        "        self.weight = nn.Parameter(torch.rand(3, 2), requires_grad=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y = torch.matmul(x, self.weight)\n",
        "\n",
        "        return y\n",
        "\n",
        "x = torch.rand(3)\n",
        "model = SingleLayerNet()\n",
        "y = model(x)\n",
        "\n",
        "print(\"x: {}\".format(x))\n",
        "print(\"y: {}\".format(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNcKMqu2R2_n",
        "outputId": "3c3b853b-5b1a-4341-8fbb-b8191490d1d4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([0.7716, 0.3839, 0.5675])\n",
            "y: tensor([0.5020, 0.9659], grad_fn=<MvBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Layer Perceptrons (MLP) 실습"
      ],
      "metadata": {
        "id": "n5ma5VLXYpf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "입력 차원이 4,\n",
        "첫 번째 hidden layer의 차원이 2,\n",
        "두 번째 hidden layer의 차원이 4,\n",
        "출력 차원이 1인 3 layer 신경망을 구현하시오.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Yo6dWIUBYn34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "r8QthJKmRWUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "x = torch.rand(10, 5)\n",
        "y = torch.rand(10)\n",
        "\n",
        "x_tensor = torch.tensor(x)\n",
        "y_tensor = torch.tensor(y)\n",
        "\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size = 2,\n",
        "    shuffle=True,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "n_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for step, batch in enumerate(loader):\n",
        "        input, label = tuple(b.to(device) for b in batch)\n",
        "        print(input)\n",
        "        print(label)"
      ],
      "metadata": {
        "id": "lMIIekwhRZb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "ENo57-LXT5z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "loss_function = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "lqpPNq0vT8FE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation"
      ],
      "metadata": {
        "id": "YfVi4qfeaxZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model.train()\n",
        "\n",
        "optimizer.zero_grad()\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(\"{}: {}\\n\".format(name, param))\n",
        "\n",
        "x = torch.rand(3)\n",
        "answer = torch.tensor([100, -100], dtype=torch.float)\n",
        "\n",
        "y = model(x)\n",
        "\n",
        "loss = loss_function(answer, y)\n",
        "print(\"Loss: {}\\n\".format(loss))\n",
        "\n",
        "# Gradient를 구하는 과정\n",
        "loss.backward()\n",
        "print(\"Gradients: {}\\n\".format(model.weight.grad))\n",
        "\n",
        "# Parameter update\n",
        "optimizer.step()\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(\"{}: {}\\n\".format(name, param))"
      ],
      "metadata": {
        "id": "iGvGn7l2azP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습가능한 신경망 구현 실습"
      ],
      "metadata": {
        "id": "-KImwL0xbAet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "[0, 0] = 1\n",
        "[0, 1] = 0\n",
        "[1, 0] = 0\n",
        "[1, 1] = 1\n",
        "\n",
        "을 학습할 수 있는 신경망을 구현하시오.\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "class BasicMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BasicMLP, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(2, 4)\n",
        "        self.layer_norm = nn.LayerNorm(4)\n",
        "\n",
        "        self.linear2 = nn.Linear(4, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.linear(x)\n",
        "        h = self.layer_norm(h)\n",
        "\n",
        "        return self.linear2(h)\n",
        "\n",
        "\n",
        "train_x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "train_y = [1, 0, 0, 1]\n",
        "\n",
        "x_tensor = torch.tensor(train_x, dtype=torch.float)\n",
        "y_tensor = torch.tensor(train_y, dtype=torch.float)\n",
        "\n",
        "train_dataset = TensorDataset(x_tensor, y_tensor)\n",
        "data_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size = 1,\n",
        "    shuffle=True,\n",
        "    drop_last=False\n",
        "    )\n",
        "\n",
        "n_epochs = 1000\n",
        "\n",
        "model = BasicMLP()\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
        "\n",
        "model.train()\n",
        "for epoch in trange(n_epochs, desc=\"Training...\"):\n",
        "    for batch in data_loader:\n",
        "        x, y = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x).view(-1)\n",
        "\n",
        "        loss = loss_function(y, pred)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "print()\n",
        "print(model(torch.tensor([0, 0], dtype=torch.float)))\n",
        "print(model(torch.tensor([0, 1], dtype=torch.float)))\n",
        "print(model(torch.tensor([1, 0], dtype=torch.float)))\n",
        "print(model(torch.tensor([1, 1], dtype=torch.float)))"
      ],
      "metadata": {
        "id": "T8NqKD1hbC1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습이 되지 않는 경우?\n",
        "\n",
        "## 1. 데이터 부족\n",
        "\n",
        "## 2. 학습 파라미터 초기화 값\n",
        "\n",
        "## 3. 손실 함수\n",
        "\n",
        "## 4. Optimizer\n",
        "\n",
        "## 5. 모델 구조"
      ],
      "metadata": {
        "id": "V2_NaY7niFtI"
      }
    }
  ]
}